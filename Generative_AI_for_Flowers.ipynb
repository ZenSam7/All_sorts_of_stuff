{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "import tensorflow as tf\n",
    "import pathlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:15:15.113028100Z",
     "start_time": "2024-04-10T12:15:13.667890Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаём датасет с цветочками"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# (лучше загрузить свой с инета)\n",
    "data_dir = tf.keras.utils.get_file(origin=\"C:\\\\Users\\\\samki\\\\Downloads\\\\flowers.zip\",\n",
    "                                   fname=\"flower_photos\",\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# Константы\n",
    "batch_size = 20\n",
    "img_height = img_width = 192\n",
    "\n",
    "# Разбиваем датасет на тренировочную группу и группу валидации\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=5432,\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=5432,\n",
    ")\n",
    "\n",
    "\n",
    "train_data = train_data.map(lambda x, y: (x / 255.0, x / 255.0))\n",
    "validation_data = validation_data.map(lambda x, y: (x / 255.0, x / 255.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:16:01.782029500Z",
     "start_time": "2024-04-10T12:16:01.451198700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 16) for input KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name='input_88'), name='input_88', description=\"created by layer 'input_88'\"), but it was called on an input with incompatible shape (None, 192, 192, 16).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"decoder\" (type Functional).\n\nInput 0 of layer \"batch_normalization_494\" is incompatible with the layer: expected ndim=2, found ndim=4. Full shape received: (None, 192, 192, 32)\n\nCall arguments received by layer \"decoder\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 192, 192, 16), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 63\u001B[0m\n\u001B[0;32m     60\u001B[0m decoder \u001B[38;5;241m=\u001B[39m Model(z, output_img, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# VAE модель\u001B[39;00m\n\u001B[1;32m---> 63\u001B[0m vae \u001B[38;5;241m=\u001B[39m Model(input_img, \u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvae\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvae_loss\u001B[39m(x, decoded):\n\u001B[0;32m     66\u001B[0m     x \u001B[38;5;241m=\u001B[39m K\u001B[38;5;241m.\u001B[39mreshape(x, shape\u001B[38;5;241m=\u001B[39m(batch_size, img_width \u001B[38;5;241m*\u001B[39m img_height \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m3\u001B[39m))\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    230\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m shape\u001B[38;5;241m.\u001B[39mrank\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m!=\u001B[39m spec\u001B[38;5;241m.\u001B[39mndim:\n\u001B[1;32m--> 232\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    233\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    234\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, found ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    236\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         )\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mmax_ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    239\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer \"decoder\" (type Functional).\n\nInput 0 of layer \"batch_normalization_494\" is incompatible with the layer: expected ndim=2, found ndim=4. Full shape received: (None, 192, 192, 32)\n\nCall arguments received by layer \"decoder\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 192, 192, 16), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "from keras.layers import (Input, Dense, Conv2D, Conv2DTranspose, BatchNormalization,\n",
    "                          Dropout, Flatten, Reshape, Lambda, MaxPool2D, Concatenate)\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "\n",
    "latent_dim = 16\n",
    "dropout = 0.1\n",
    "\n",
    "# Энкодер\n",
    "input_img = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "x = Dense(latent_dim*16, activation=\"relu\")(input_img)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "x = Dense(latent_dim*8, activation=\"relu\")(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "x = Dense(latent_dim*4, activation=\"relu\")(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "x = Dense(latent_dim*2, activation=\"relu\")(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "z_mean = Dense(latent_dim, activation=\"sigmoid\")(x)\n",
    "z_log_var = Dense(latent_dim, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Сэмплирование из Q с трюком репараметризации\n",
    "@tf.function\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "    return z_mean + tf.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(input_img, l, \"encoder\")\n",
    "\n",
    "# Декодер\n",
    "z = Input(shape=(latent_dim, ))\n",
    "\n",
    "x = Dense(latent_dim*2)(z)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "x = Dense(latent_dim*4)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "x = Dense(latent_dim*8)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "x = Dense(latent_dim*16)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "x = Dense(img_width * img_height * 3, activation=\"sigmoid\")(x)\n",
    "output_img = Reshape((img_height, img_width, 3))(x)\n",
    "\n",
    "decoder = Model(z, output_img, name=\"decoder\")\n",
    "\n",
    "# VAE модель\n",
    "vae = Model(input_img, decoder(l), name=\"vae\")\n",
    "\n",
    "def vae_loss(x, decoded):\n",
    "    x = K.reshape(x, shape=(batch_size, img_width * img_height * 3))\n",
    "    decoded = K.reshape(decoded, shape=(batch_size, img_width * img_height * 3))\n",
    "\n",
    "    xent_loss = img_width * img_height * 3 * binary_crossentropy(x, decoded)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return (xent_loss + kl_loss) / 2 / img_width / img_height / 3\n",
    "\n",
    "vae.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T16:17:23.262081500Z",
     "start_time": "2024-04-10T16:17:23.075082700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "147/147 [==============================] - 67s 438ms/step - loss: 0.6419 - val_loss: 0.6536\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 62s 421ms/step - loss: 0.5960 - val_loss: 0.6281\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 62s 421ms/step - loss: 0.5871 - val_loss: 0.6855\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 62s 423ms/step - loss: 0.5811 - val_loss: 0.6568\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 62s 421ms/step - loss: 0.5768 - val_loss: 0.7127\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 62s 423ms/step - loss: 0.5729 - val_loss: 0.6276\n",
      "Epoch 7/10\n",
      "  1/147 [..............................] - ETA: 1:01 - loss: 0.5627"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mvae\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[0;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[1;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[1;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[0;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[1;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\callbacks.py:1157\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1153\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m add_seen\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen, \u001B[38;5;28mlist\u001B[39m(logs\u001B[38;5;241m.\u001B[39mitems()), finalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m--> 635\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 628\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \n\u001B[0;32m   1136\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1122\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "vae.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=validation_data,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T12:32:11.585866500Z",
     "start_time": "2024-04-10T12:25:53.303973300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Генерация изображений с помощью автоэнкодера\n",
    "generated_images = vae.predict(validation_data)\n",
    "num_images = 10\n",
    "\n",
    "# Конвертируем в список\n",
    "validation_img = generated_img = []\n",
    "for img, _ in validation_data:\n",
    "    validation_img.extend(img.numpy())\n",
    "\n",
    "# Отображение сгенерированных изображений\n",
    "plt.figure(figsize=(17, 4))\n",
    "for i in range(num_images):\n",
    "    # Исходное изображение\n",
    "    plt.subplot(2, num_images, i + 1)\n",
    "    plt.imshow(validation_img[i])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Сгенерированное изображение\n",
    "    plt.subplot(2, num_images, i + num_images + 1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
