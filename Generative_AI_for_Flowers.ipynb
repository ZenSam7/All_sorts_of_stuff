{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "import tensorflow as tf\n",
    "import pathlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создаём датасет с цветочками"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin=\"C:\\\\Users\\\\samki\\\\Downloads\\\\flowers.zip\",\n",
    "                                   fname=\"flower_photos\",\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# Константы\n",
    "batch_size = 20\n",
    "img_height = img_width = 128\n",
    "\n",
    "# Разбиваем датасет на тренировочную группу и группу валидации\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=5432,\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed=5432,\n",
    ")\n",
    "\n",
    "# Нормализуем в [0; 1], + убираем лейблы (т.к. у нас задача не распознавать изображения)\n",
    "train_data = train_data.map(lambda x, y: (x / 255.0, x / 255.0))\n",
    "validation_data = validation_data.map(lambda x, y: (x / 255.0, x / 255.0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import (Input, Dense, Conv2D, Conv2DTranspose, BatchNormalization, UpSampling2D,\n",
    "                          Dropout, Flatten, Reshape, Lambda, MaxPool2D, Concatenate)\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "\n",
    "# Константы\n",
    "filters = 64\n",
    "hidden_units = 1024\n",
    "dropout = 0.0\n",
    "\n",
    "# Энкодер\n",
    "input_img = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "def encode_layer(x):\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "    x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "x = encode_layer(input_img)\n",
    "x = encode_layer(x)\n",
    "x = encode_layer(x)\n",
    "x = encode_layer(x)\n",
    "x = encode_layer(x)\n",
    "x = Flatten()(x)\n",
    "encoder_output = Dense(hidden_units)(x)\n",
    "\n",
    "# Декодер\n",
    "def decode_layer(x):\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "    x = Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = Dropout(dropout)(BatchNormalization()(x))\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    return x\n",
    "\n",
    "x = Reshape((32, 32, 1))(encoder_output)\n",
    "x = decode_layer(x)\n",
    "x = decode_layer(x)\n",
    "x = decode_layer(x)\n",
    "x = decode_layer(x)\n",
    "x = decode_layer(x)\n",
    "\n",
    "x = Conv2D(3, (11, 11), activation=\"sigmoid\", padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(img_height * img_width * 3, activation=\"sigmoid\", kernel_initializer=\"he_normal\")(x)\n",
    "output_img = Reshape((img_height, img_width, 3))(x)\n",
    "\n",
    "# Модели\n",
    "vae = Model(input_img, output_img, name=\"vae\")\n",
    "\n",
    "vae.compile(\n",
    "    optimizer=Adam(3e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    # loss_weights=[100],\n",
    ")\n",
    "\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vae.fit(\n",
    "    train_data,\n",
    "    epochs=20,\n",
    "    validation_data=validation_data,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "# Генерация изображений с помощью автоэнкодера\n",
    "# validation_data = train_data\n",
    "\n",
    "# Конвертируем в список\n",
    "validation_img = generated_img = []\n",
    "for img, _ in validation_data:\n",
    "    validation_img.extend(img.numpy())\n",
    "\n",
    "generated_images = vae.predict(np.array(validation_img))\n",
    "num_images = 10\n",
    "\n",
    "# Отображение сгенерированных изображений\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i in range(num_images):\n",
    "    random_num = randint(0, len(validation_img))\n",
    "    # Исходное изображение\n",
    "    plt.subplot(2, num_images, i + 1)\n",
    "    plt.imshow(validation_img[random_num])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Сгенерированное изображение\n",
    "    plt.subplot(2, num_images, i + num_images + 1)\n",
    "    plt.imshow(generated_images[random_num])\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
