{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:09:04.945782400Z",
     "start_time": "2024-05-11T08:09:03.575261500Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создаём датасет с цветочками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:09:04.961541200Z",
     "start_time": "2024-05-11T08:09:04.948784500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Константы\n",
    "img_side = 204\n",
    "\n",
    "# Разбиваем датасет на тренировочную группу и группу валидации\n",
    "def init_data_with_batch_size(batch_size, dataset=\"flowers\"):\n",
    "    \"\"\"Чтобы использовать \"new_flowers\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "    train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset,\n",
    "        image_size=(img_side, img_side),\n",
    "        label_mode=\"int\",  # Тут не \"categorical\" т.к. мы испольлзауем Embedding\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Добавляем лейблы (т.к. у нас Cgan) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "    # (не sigmoid, а tanh, т.к. с ним градиент не затухает)\n",
    "    x = np.array([i[0]/127.5 -1 for i in train_data][:-1])\n",
    "    y = np.array([i[1] for i in train_data][:-1])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               63922688  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,448,513\n",
      "Trainable params: 64,448,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 124848)            32085936  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 204, 204, 3)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,131,184\n",
      "Trainable params: 32,130,288\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "\n",
      "Generator    : 32,131,216\n",
      "Discriminator: 64,573,361\n",
      "Sum:           96,704,577\n"
     ]
    }
   ],
   "source": [
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_shape = (img_side, img_side, 3)\n",
    "        self.num_classes = 5\n",
    "        self.latent_dim = 32\n",
    "\n",
    "        optimizer = Adam(4e-4, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(\n",
    "            loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(64, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(128))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(1, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(1, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, data, batch_size, epochs, sample_interval=50):\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, img_side, batch_size)\n",
    "            imgs, labels = data[0][idx], data[1][idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i, j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "cgan = CGAN()\n",
    "\n",
    "print()\n",
    "print(\"Generator    :\", f\"{cgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{cgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{cgan.generator.count_params() + cgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T08:09:05.740536900Z",
     "start_time": "2024-05-11T08:09:05.051537600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T08:09:08.725562200Z",
     "start_time": "2024-05-11T08:09:05.741538100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 files belonging to 5 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 100)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m init_data_with_batch_size(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflowers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mcgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 112\u001B[0m, in \u001B[0;36mCGAN.train\u001B[1;34m(self, data, batch_size, epochs, sample_interval)\u001B[0m\n\u001B[0;32m    109\u001B[0m noise \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, (batch_size, \u001B[38;5;241m100\u001B[39m))\n\u001B[0;32m    111\u001B[0m \u001B[38;5;66;03m# Generate a half batch of new images\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m gen_imgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# Train the discriminator\u001B[39;00m\n\u001B[0;32m    115\u001B[0m d_loss_real \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mtrain_on_batch([imgs, labels], valid)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\Temp\\__autograph_generated_filemqpfi75t.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 100)\n"
     ]
    }
   ],
   "source": [
    "data = init_data_with_batch_size(1, \"flowers\")\n",
    "\n",
    "cgan.train(data, 16, 20000, sample_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_row_images(raw_data):\n",
    "    # Ограничиваемся только 32 восстановленными изображениями (чтобы считать меньше)\n",
    "    data = np.array([i[0][0] for count, i in enumerate(raw_data) if count < 32])\n",
    "    labels = np.array([i[1][0] for count, i in enumerate(raw_data) if count < 32])\n",
    "    _, _, encoded = encoder.predict([data, labels], verbose=False)\n",
    "    generated_images = decoder.predict([encoded, labels], verbose=False)\n",
    "\n",
    "    num_images = 4\n",
    "\n",
    "    plt.figure(figsize=(20, 11))\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        random_num = randint(0, 32-1)\n",
    "\n",
    "        # Оригинальное изображение\n",
    "        plt.subplot(2, num_images, _ + 1)\n",
    "        plt.imshow(data[random_num])\n",
    "        plt.gray()\n",
    "        plt.title(\"Train\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Сгенерированное изображение\n",
    "        plt.subplot(2, num_images, _ + num_images + 1)\n",
    "        plt.imshow(generated_images[random_num])\n",
    "        plt.gray()\n",
    "        plt.title(\"Generated\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "raw_data = init_data_with_batch_size(1, \"flowers\")\n",
    "for _ in range(3):\n",
    "    show_row_images(raw_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = init_data_with_batch_size(1, \"flowers\")\n",
    "data = np.array([next(iter(d))[0][0] for _ in range(1000)])\n",
    "labels = np.array([next(iter(d))[1][0] for _ in range(1000)])\n",
    "\n",
    "_, _, all_hidden_data = encoder.predict([data, labels])\n",
    "mean, std = np.mean(all_hidden_data), np.std(all_hidden_data)\n",
    "print(\"mean (ideal: 0):\", mean)\n",
    "print(\"std  (ideal: 1):\", std)\n",
    "\n",
    "for _ in range(4):\n",
    "    num_images = 4\n",
    "\n",
    "    noise = np.random.normal(mean, std, [num_images*2, hidden_units])\n",
    "    label = np.array([ keras.utils.to_categorical(np.random.randint(0, 5), 5)\n",
    "                       for _ in range(num_images*2)])\n",
    "    generated_images = np.array(decoder.predict([noise, label], verbose=False))\n",
    "\n",
    "    plt.figure(figsize=(20, 11))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Оригинальное изображение\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "\n",
    "        # Переводим в промежуток [0; 1]\n",
    "        plt.imshow(generated_images[i + num_images])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Сгенерированное изображение\n",
    "        plt.subplot(2, num_images, i + num_images + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Выводим Архитектуру\"\"\"\n",
    "encoder_img = tf.keras.utils.plot_model(encoder, to_file=\"encoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)\n",
    "\n",
    "decoder_img = tf.keras.utils.plot_model(decoder, to_file=\"decoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cgan.save_weights(\"cgan\")\n",
    "# cgan.load_weights(\"cgan\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
