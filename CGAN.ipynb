{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создаём датасет с цветочками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "img_side = 204\n",
    "\n",
    "# Разбиваем датасет на тренировочную группу и группу валидации\n",
    "def init_data_with_batch_size(batch_size, dataset=\"flowers\"):\n",
    "    \"\"\"Чтобы использовать \"new_flowers\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "    train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "        dataset,\n",
    "        image_size=(img_side, img_side),\n",
    "        label_mode=\"int\",  # Тут не \"categorical\" т.к. мы испольлзауем Embedding\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # Добавляем лейблы (т.к. у нас Cgan) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "    # (не sigmoid, а tanh, т.к. с ним градиент не затухает)\n",
    "    x = np.array([i[0]/127.5 -1 for i in train_data][:-1])\n",
    "    y = np.array([i[1] for i in train_data][:-1])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_shape = (img_side, img_side, 3)\n",
    "        self.num_classes = 5\n",
    "        self.latent_dim = 32\n",
    "\n",
    "        optimizer = Adam(4e-4, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(\n",
    "            loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(\n",
    "            loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(64, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(128))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(1, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(1, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, data, batch_size, epochs, sample_interval=50):\n",
    "        for epoch in range(epochs):\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, img_side, batch_size)\n",
    "            imgs, labels = data[0][idx], data[1][idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i, j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "cgan = CGAN()\n",
    "\n",
    "print()\n",
    "print(\"Generator    :\", f\"{cgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{cgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{cgan.generator.count_params() + cgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = init_data_with_batch_size(1, \"flowers\")\n",
    "\n",
    "cgan.train(data, 16, 20000, sample_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_row_images(raw_data):\n",
    "    # Ограничиваемся только 32 восстановленными изображениями (чтобы считать меньше)\n",
    "    data = np.array([i[0][0] for count, i in enumerate(raw_data) if count < 32])\n",
    "    labels = np.array([i[1][0] for count, i in enumerate(raw_data) if count < 32])\n",
    "    _, _, encoded = encoder.predict([data, labels], verbose=False)\n",
    "    generated_images = decoder.predict([encoded, labels], verbose=False)\n",
    "\n",
    "    num_images = 4\n",
    "\n",
    "    plt.figure(figsize=(20, 11))\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        random_num = randint(0, 32-1)\n",
    "\n",
    "        # Оригинальное изображение\n",
    "        plt.subplot(2, num_images, _ + 1)\n",
    "        plt.imshow(data[random_num])\n",
    "        plt.gray()\n",
    "        plt.title(\"Train\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Сгенерированное изображение\n",
    "        plt.subplot(2, num_images, _ + num_images + 1)\n",
    "        plt.imshow(generated_images[random_num])\n",
    "        plt.gray()\n",
    "        plt.title(\"Generated\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "raw_data = init_data_with_batch_size(1, \"flowers\")\n",
    "for _ in range(3):\n",
    "    show_row_images(raw_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = init_data_with_batch_size(1, \"flowers\")\n",
    "data = np.array([next(iter(d))[0][0] for _ in range(1000)])\n",
    "labels = np.array([next(iter(d))[1][0] for _ in range(1000)])\n",
    "\n",
    "_, _, all_hidden_data = encoder.predict([data, labels])\n",
    "mean, std = np.mean(all_hidden_data), np.std(all_hidden_data)\n",
    "print(\"mean (ideal: 0):\", mean)\n",
    "print(\"std  (ideal: 1):\", std)\n",
    "\n",
    "for _ in range(4):\n",
    "    num_images = 4\n",
    "\n",
    "    noise = np.random.normal(mean, std, [num_images*2, hidden_units])\n",
    "    label = np.array([ keras.utils.to_categorical(np.random.randint(0, 5), 5)\n",
    "                       for _ in range(num_images*2)])\n",
    "    generated_images = np.array(decoder.predict([noise, label], verbose=False))\n",
    "\n",
    "    plt.figure(figsize=(20, 11))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Оригинальное изображение\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "\n",
    "        # Переводим в промежуток [0; 1]\n",
    "        plt.imshow(generated_images[i + num_images])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Сгенерированное изображение\n",
    "        plt.subplot(2, num_images, i + num_images + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Выводим Архитектуру\"\"\"\n",
    "encoder_img = tf.keras.utils.plot_model(encoder, to_file=\"encoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)\n",
    "\n",
    "decoder_img = tf.keras.utils.plot_model(decoder, to_file=\"decoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cgan.save_weights(\"cgan\")\n",
    "# cgan.load_weights(\"cgan\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
