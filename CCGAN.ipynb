{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T18:11:44.936022200Z",
     "start_time": "2024-05-30T18:11:43.448473700Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 5, 26896)     134480      ['label[0][0]']                  \n",
      "                                                                                                  \n",
      " image (InputLayer)             [(None, 164, 164, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " reshape_30 (Reshape)           (None, 164, 164, 5)  0           ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 164, 164, 8)  0           ['image[0][0]',                  \n",
      "                                                                  'reshape_30[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_48 (MaxPooling2D  (None, 82, 82, 8)   0           ['concatenate_90[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 82, 82, 8)    0           ['max_pooling2d_48[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 79, 79, 16)   2064        ['dropout_136[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_49 (MaxPooling2D  (None, 39, 39, 16)  0           ['conv2d_108[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 39, 39, 16)   0           ['max_pooling2d_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 36, 36, 32)   8224        ['dropout_137[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_50 (MaxPooling2D  (None, 18, 18, 32)  0           ['conv2d_109[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 18, 18, 32)   0           ['max_pooling2d_50[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 15, 15, 64)   32832       ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_51 (MaxPooling2D  (None, 7, 7, 64)    0           ['conv2d_110[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 7, 7, 64)     0           ['max_pooling2d_51[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 4, 4, 128)    131200      ['dropout_139[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)           (None, 2048)         0           ['conv2d_111[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 2048)         0           ['flatten_14[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 2053)         0           ['label[0][0]',                  \n",
      "                                                                  'dropout_140[0][0]']            \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 32)           65728       ['concatenate_91[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 32)           0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 37)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_141[0][0]']            \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 16)           608         ['concatenate_92[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 16)           0           ['dense_75[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 21)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 8)            176         ['concatenate_93[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 8)            0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 13)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 4)            56          ['concatenate_94[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 9)            0           ['label[0][0]',                  \n",
      "                                                                  'dense_77[0][0]']               \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 1)            10          ['concatenate_95[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 375,378\n",
      "Trainable params: 375,378\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " latent_space (InputLayer)      [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 21)           0           ['latent_space[0][0]',           \n",
      "                                                                  'label[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 36)           792         ['concatenate_96[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_31 (Reshape)           (None, 6, 6, 1)      0           ['dense_79[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 6, 6, 1)      0           ['reshape_31[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_70 (Conv2DTra  (None, 14, 14, 128)  2176       ['dropout_144[0][0]']            \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 11, 11, 128)  262272      ['conv2d_transpose_70[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 11, 11, 128)  512        ['conv2d_112[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 11, 11, 128)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_71 (Conv2DTra  (None, 24, 24, 64)  131136      ['dropout_145[0][0]']            \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 21, 21, 64)   65600       ['conv2d_transpose_71[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 21, 21, 64)  256         ['conv2d_113[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 21, 21, 64)   0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_72 (Conv2DTra  (None, 44, 44, 32)  32800       ['dropout_146[0][0]']            \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 41, 41, 32)   16416       ['conv2d_transpose_72[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 41, 41, 32)  128         ['conv2d_114[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 41, 41, 32)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_73 (Conv2DTra  (None, 84, 84, 16)  8208        ['dropout_147[0][0]']            \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 81, 81, 16)   4112        ['conv2d_transpose_73[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 81, 81, 16)  64          ['conv2d_115[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_74 (Conv2DTra  (None, 164, 164, 3)  771        ['batch_normalization_75[0][0]'] \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 525,243\n",
      "Trainable params: 524,763\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "Generator:     525,243\n",
      "Discriminator: 375,378\n",
      "Sum:           900,621\n"
     ]
    }
   ],
   "source": [
    "# Удаляем все прошлые изображения\n",
    "for i in os.listdir(\"./generated_flowers\"):\n",
    "    os.remove(f\"./generated_flowers/{i}\")\n",
    "\n",
    "class CCGAN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.NUM_CLASSES = 5  # Не менять!\n",
    "\n",
    "        # Входные форматы\n",
    "        self.IMG_SHAPE = (164, 164, 3)\n",
    "        self.LATENT_DIM = 16\n",
    "\n",
    "        # Константы\n",
    "        self.FILTERS = 16  # Нижняя граница\n",
    "        self.DROPOUT = 0.1\n",
    "        self.HIDDEN_IMG_SHAPE = (6, 6, 1)\n",
    "        self.HANDICAP = 3  # Фора в опережении одной из нейронок перед другой\n",
    "\n",
    "        # Чем меньше тем лучше:\n",
    "        self.AMOUNT_DISCRIMINATOR_LAYERS = 4\n",
    "        self.AMOUNT_GENERATOR_LAYERS = 4\n",
    "\n",
    "        \"\"\"\n",
    "        Генератор и Дискриминатор\n",
    "        \"\"\"\n",
    "        # Мучаемся со входами\n",
    "        self.image_inp = Input(shape=self.IMG_SHAPE, name=\"image\")\n",
    "        self.label_inp = Input(shape=(self.NUM_CLASSES,), name=\"label\")\n",
    "        self.latent_space_inp = Input(shape=(self.LATENT_DIM,), name=\"latent_space\")\n",
    "\n",
    "        # Создаём дискриминатор\n",
    "        self.build_discriminator()\n",
    "        self.discriminator.summary()\n",
    "        # Создаём генератор\n",
    "        self.build_generator()\n",
    "        self.generator.summary()\n",
    "\n",
    "        \"\"\"\n",
    "        Модели\n",
    "        \"\"\"\n",
    "        # z == latten_space\n",
    "        self.generated_z = self.generator([self.latent_space_inp, self.label_inp])\n",
    "        self.dis_gen_z = self.discriminator([self.generated_z, self.label_inp])\n",
    "\n",
    "        ccgan_model = Model([self.latent_space_inp, self.label_inp], self.dis_gen_z, name=\"CCGAN\")\n",
    "        self.ccgan = ccgan_model([self.latent_space_inp, self.label_inp])\n",
    "\n",
    "        self.optimizer_gen = Adam(1e-3)\n",
    "        self.optimizer_dis = Adam(1e-3)\n",
    "\n",
    "    def build_discriminator(self) -> Model:\n",
    "        x = Embedding(self.NUM_CLASSES, self.IMG_SHAPE[0]**2)(self.label_inp)\n",
    "        x = Reshape([*self.IMG_SHAPE[:2], self.NUM_CLASSES])(x)\n",
    "        x = concatenate([self.image_inp, x])\n",
    "\n",
    "        for i in range(self.AMOUNT_DISCRIMINATOR_LAYERS):\n",
    "            x = MaxPool2D()(x)\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            # x = Conv2D(self.FILTERS * 2**i, (4, 4), activation=\"relu\", strides=1)(x)\n",
    "            x = Conv2D(self.FILTERS * 2**i, (4, 4), activation=\"relu\", strides=1)(x)\n",
    "            # x = BatchNormalization()(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        for i in range(4):\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "            x = Dense(32 // 2**i, activation=\"relu\")(x)\n",
    "\n",
    "        x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.discriminator = Model([self.image_inp, self.label_inp], x, name=\"discriminator\")\n",
    "\n",
    "    def build_generator(self) -> Model:\n",
    "        x = self.latent_space_inp\n",
    "\n",
    "        x = concatenate([x, self.label_inp])\n",
    "        x = Dense(np.prod(self.HIDDEN_IMG_SHAPE))(x)\n",
    "        x = Reshape(self.HIDDEN_IMG_SHAPE)(x)\n",
    "\n",
    "        for i in range(self.AMOUNT_GENERATOR_LAYERS -1, -1, -1):\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            x = Conv2DTranspose(self.FILTERS * 2**i, (4, 4), activation=\"relu\", strides=2)(x)\n",
    "            x = Conv2D(self.FILTERS * 2**i, (4, 4), activation=\"relu\", strides=1)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        generated_img = Conv2DTranspose(3, (4, 4), activation=\"tanh\", strides=2)(x)\n",
    "\n",
    "        self.generator = Model([self.latent_space_inp, self.label_inp], generated_img, name=\"generator\")\n",
    "\n",
    "    def batch_gen(self, batch_size, dataset):\n",
    "        \"\"\"Чтобы использовать \"big_flowers_dataset\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "        train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            image_size=self.IMG_SHAPE[:-1],\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            # Добавляем лейблы (т.к. у нас CCGAN) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "            # (т.к. с sigmoid градиент затухает)\n",
    "            x, y = next(iter(train_data))\n",
    "            x = x / 127.5 -1\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.LATENT_DIM))\n",
    "\n",
    "            yield x, y, noise\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        row, column = 2, self.NUM_CLASSES\n",
    "        noise = np.random.normal(0, 1, (row * column, self.LATENT_DIM))\n",
    "        label = np.array([\n",
    "            np.arange(0, self.NUM_CLASSES) for _ in range(row)\n",
    "        ]).reshape((-1, 1))\n",
    "        sampled_labels = keras.utils.to_categorical(label, self.NUM_CLASSES)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels], verbose=False)\n",
    "        gen_imgs = (gen_imgs + 1) / 2\n",
    "\n",
    "        # Делаем картинку\n",
    "        fig, axs = plt.subplots(row, column, figsize=(12, 6))\n",
    "        count = 0\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                axs[i, j].imshow(gen_imgs[count, :, :, :])\n",
    "                axs[i, j].set_title(label[count][0])\n",
    "                axs[i, j].axis(\"off\")\n",
    "                count += 1\n",
    "        fig.savefig(\"generated_flowers/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def train(self, batch_size=32, dataset=\"flowers_dataset\"):\n",
    "        # Просто единицы и нули для Дискриминатора\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        get_batch = self.batch_gen(batch_size=batch_size, dataset=dataset)\n",
    "\n",
    "        epoch_count = 0\n",
    "        all_l_dis = [0]\n",
    "        all_l_gen = [0]\n",
    "\n",
    "        for learn_iter in range(int(10**10)):\n",
    "            # Если Генератор обыгрывает Дискриминатор, то обучаем Дискриминатор\n",
    "            iters = self.HANDICAP if np.mean(all_l_dis) > np.mean(all_l_gen) else 1\n",
    "            for _ in range(iters):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as dis_tape:\n",
    "                    dis_real_output = self.discriminator([images, labels], training=True)\n",
    "                    generated_images = self.generator([noise, labels], training=False)\n",
    "                    dis_fake_output = self.discriminator([generated_images, labels], training=True)\n",
    "\n",
    "                    # Чем настоящие картинки нереальнее или сгенерированные реальные, тем ошибка больше\n",
    "                    l_dis = 0.5 * (tf.reduce_mean(-tf.math.log(dis_real_output + 1e-9)) +\n",
    "                                   tf.reduce_mean(-tf.math.log(1. - dis_fake_output + 1e-9)))\n",
    "\n",
    "                all_l_dis.append(l_dis)\n",
    "\n",
    "                # Получаем градиенты для дискриминатора\n",
    "                grads_dis = dis_tape.gradient(l_dis, self.discriminator.trainable_variables)\n",
    "                self.optimizer_dis.apply_gradients(zip(grads_dis, self.discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "            # Если Дискриминатор обыгрывает Генератор, то больше обучаем Генератор\n",
    "            iters = self.HANDICAP if np.mean(all_l_gen) > np.mean(all_l_dis) else 1\n",
    "            for _ in range(iters):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as gen_tape:\n",
    "                    generated_images = self.generator([noise, labels], training=True)\n",
    "                    dis_output = self.discriminator([generated_images, labels], training=False)\n",
    "\n",
    "                    # Чем более реалистичная картина (для дискриминатора), тем меньше ошибка\n",
    "                    l_gen = -tf.reduce_mean(tf.math.log(dis_output + 1e-9))\n",
    "\n",
    "                all_l_gen.append(l_gen)\n",
    "\n",
    "                # Получаем градиенты для генератора\n",
    "                grads_gen = gen_tape.gradient(l_gen, self.generator.trainable_variables)\n",
    "                self.optimizer_gen.apply_gradients(zip(grads_gen, self.generator.trainable_variables))\n",
    "\n",
    "            # ______________________________\n",
    "            # Сохраняем генерируемые образцы каждую эпоху\n",
    "            if learn_iter % (2800 // batch_size) == 0:\n",
    "                self.sample_images(epoch_count)\n",
    "\n",
    "                # Вывод прогресса и средних ошибок\n",
    "                print(f\"{epoch_count:02} \\t\"\n",
    "                      f\"[Dis loss: {np.mean(all_l_dis):.3f}] \\t\"\n",
    "                      f\"[Gen loss: {np.mean(all_l_gen):.3f}]\")\n",
    "\n",
    "                epoch_count += 1\n",
    "                all_l_dis = [0]\n",
    "                all_l_gen = [0]\n",
    "\n",
    "ccgan = CCGAN()\n",
    "print(\"Generator:    \", f\"{ccgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{ccgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{ccgan.generator.count_params() + ccgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T18:17:57.611302900Z",
     "start_time": "2024-05-30T18:17:57.313622700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-30T18:17:59.289188400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 files belonging to 5 classes.\n",
      "00 \t[Dis loss: 0.384] \t[Gen loss: 0.387]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ccgan.train(batch_size=64, dataset=\"flowers_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Выводим Архитектуру\"\"\"\n",
    "encoder_img = tf.keras.utils.plot_model(encoder, to_file=\"encoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)\n",
    "\n",
    "decoder_img = tf.keras.utils.plot_model(decoder, to_file=\"decoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccgan.save_weights(\"ccgan\")\n",
    "# ccgan.load_weights(\"ccgan\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
