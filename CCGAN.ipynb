{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T10:53:43.275127700Z",
     "start_time": "2024-06-06T10:53:43.260127300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 170, 170, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 170, 170, 3)  12         ['image[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 85, 85, 3)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 85, 85, 3)   12          ['max_pooling2d[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 85, 85, 3)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 83, 83, 32)   896         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 81, 81, 32)   9248        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 79, 79, 32)   9248        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 77, 77, 32)   9248        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 75, 75, 32)   9248        ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 37, 37, 32)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 37, 37, 32)  128         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 37, 37, 32)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   18496       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 33, 33, 64)   36928       ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 31, 31, 64)   36928       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 29, 29, 64)   36928       ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 27, 27, 64)   36928       ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 64)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 13, 13, 64)  256         ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 13, 13, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 11, 11, 128)  73856       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 9, 9, 128)    147584      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 7, 128)    147584      ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 5, 5, 128)    147584      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 3, 3, 128)    147584      ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 3, 3, 128)   512         ['conv2d_14[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 3, 3, 128)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 1, 128)    147584      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128)         512         ['flatten[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 133)          0           ['label[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8576        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64)          256         ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 69)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           2240        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32)          128         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32)           0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 37)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           608         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16)          64          ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16)           0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 21)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 8)            176         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8)           32          ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 8)            0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 13)           0           ['label[0][0]',                  \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4)            56          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 9)            0           ['label[0][0]',                  \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            10          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,029,450\n",
      "Trainable params: 1,028,494\n",
      "Non-trainable params: 956\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " latent_space (InputLayer)      [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8)           32          ['latent_space[0][0]']           \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 8)            0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 13)           0           ['dropout_9[0][0]',              \n",
      "                                                                  'label[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 26)           364         ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 26)          104         ['dense_6[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 26)           0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 31)           0           ['dropout_10[0][0]',             \n",
      "                                                                  'label[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 62)           1984        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 62)          248         ['dense_7[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 62)           0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 67)           0           ['dropout_11[0][0]',             \n",
      "                                                                  'label[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 134)          9112        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 139)          0           ['dense_8[0][0]',                \n",
      "                                                                  'label[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 6400)         896000      ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 80, 80, 1)    0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 80, 80, 1)   4           ['reshape[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 160, 160, 1)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 162, 162, 80  800        ['up_sampling2d[0][0]']          \n",
      " ose)                           )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 164, 164, 80  57680      ['conv2d_transpose[0][0]']       \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 166, 166, 80  57680      ['conv2d_transpose_1[0][0]']     \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 168, 168, 80  57680      ['conv2d_transpose_2[0][0]']     \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 170, 170, 80  57680      ['conv2d_transpose_3[0][0]']     \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 172, 172, 80  57680      ['conv2d_transpose_4[0][0]']     \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 172, 172, 80  320        ['conv2d_transpose_5[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 170, 170, 3)  2163        ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,199,531\n",
      "Trainable params: 1,199,177\n",
      "Non-trainable params: 354\n",
      "__________________________________________________________________________________________________\n",
      "Generator:     1,199,531\n",
      "Discriminator: 1,029,450\n",
      "Sum:           2,228,981\n"
     ]
    }
   ],
   "source": [
    "# Удаляем все прошлые изображения\n",
    "for i in os.listdir(\"./generated_flowers\"):\n",
    "    os.remove(f\"./generated_flowers/{i}\")\n",
    "\n",
    "class CCGAN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.NUM_CLASSES = 5  # Не менять!\n",
    "\n",
    "        # Входные форматы\n",
    "        self.IMG_SHAPE = (170, 170, 3)\n",
    "        self.LATENT_DIM = 8\n",
    "        self.HANDICAP = 5  # Фора чтобы одна иишка не отставала от другой\n",
    "\n",
    "        # Константы\n",
    "        self.FILTERS_DIS = 16  # Нижняя граница\n",
    "        self.FILTERS_GEN = 80\n",
    "        self.DROPOUT = 0.2\n",
    "        self.HIDDEN_IMG_SHAPE = (80, 80, 1)\n",
    "\n",
    "        # Чем меньше тем лучше:\n",
    "        self.AMOUNT_DISCRIMINATOR_LAYERS = 3\n",
    "        self.AMOUNT_GENERATOR_LAYERS = 3\n",
    "\n",
    "        \"\"\"\n",
    "        Генератор и Дискриминатор\n",
    "        \"\"\"\n",
    "        # Мучаемся со входами\n",
    "        self.image_inp = Input(shape=self.IMG_SHAPE, name=\"image\")\n",
    "        self.label_inp = Input(shape=(self.NUM_CLASSES,), name=\"label\")\n",
    "        self.latent_space_inp = Input(shape=(self.LATENT_DIM,), name=\"latent_space\")\n",
    "\n",
    "        # Создаем дискриминатор\n",
    "        self.build_discriminator()\n",
    "        self.discriminator.summary()\n",
    "        # Создаем генератор\n",
    "        self.build_generator()\n",
    "        self.generator.summary()\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.decode_loss_tracker = keras.metrics.Mean(name=\"decode_loss\")\n",
    "        self.bias_loss_tracker = keras.metrics.Mean(name=\"bias_loss\")\n",
    "\n",
    "        \"\"\"\n",
    "        Модели\n",
    "        \"\"\"\n",
    "        # z == latten_space (зображение между нейронками, которое мы выводим)\n",
    "        self.generated_z = self.generator([self.latent_space_inp, self.label_inp])\n",
    "        self.dis_gen_z = self.discriminator([self.generated_z, self.label_inp])\n",
    "\n",
    "        self.ccgan = Model([self.latent_space_inp, self.label_inp], self.dis_gen_z, name=\"CCGAN\")\n",
    "\n",
    "        self.ccgan.compile(Adam(1e-3), loss=\"binary_crossentropy\")\n",
    "        self.generator.compile(Adam(1e-3), loss=\"binary_crossentropy\")\n",
    "        self.discriminator.compile(Adam(1e-3), loss=\"binary_crossentropy\")\n",
    "\n",
    "        self.optimizer_gen = Adam(1e-3)\n",
    "        self.optimizer_dis = Adam(1e-3)\n",
    "\n",
    "    def build_discriminator(self) -> Model:\n",
    "        # Объединяем картинку с лейблами\n",
    "        # x = Embedding(self.NUM_CLASSES, self.IMG_SHAPE[0]**2)(self.label_inp)\n",
    "        # x = Reshape([*self.IMG_SHAPE[:2], self.NUM_CLASSES])(x)\n",
    "        # x = concatenate([BatchNormalization()(self.image_inp), x])\n",
    "        x = BatchNormalization()(self.image_inp)\n",
    "\n",
    "        for i in range(1, self.AMOUNT_DISCRIMINATOR_LAYERS +1):\n",
    "            x = MaxPooling2D()(x)\n",
    "            x = Dropout(self.DROPOUT)(BatchNormalization()(x))\n",
    "            for _ in range(5):\n",
    "                x = Conv2D(self.FILTERS_DIS * 2**i, (3, 3), activation=LeakyReLU())(x)\n",
    "\n",
    "        # Максимально сжимаем изображение\n",
    "        while x.shape[1] >= 3:\n",
    "            x = Dropout(self.DROPOUT)(BatchNormalization()(x))\n",
    "            x = Conv2D(x.shape[-1], (3, 3), activation=LeakyReLU())(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        # Постепенно сжимаем\n",
    "        dense_units = x.shape[-1] // 2\n",
    "        while dense_units >= 4:\n",
    "            x = Dropout(self.DROPOUT)(BatchNormalization()(x))\n",
    "            x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "            x = Dense(dense_units, activation=LeakyReLU())(x)\n",
    "            dense_units //= 2\n",
    "\n",
    "        # Добавляем метки класса\n",
    "        x = concatenate([self.label_inp, x])\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.discriminator = Model([self.image_inp, self.label_inp], x, name=\"discriminator\")\n",
    "\n",
    "    def build_generator(self) -> Model:\n",
    "        # Разжимаем вектор шума в маленькую картинку\n",
    "        x = self.latent_space_inp\n",
    "\n",
    "        for _ in range(self.AMOUNT_GENERATOR_LAYERS):\n",
    "            x = Dropout(self.DROPOUT)(BatchNormalization()(x))\n",
    "            x = concatenate([x, self.label_inp])\n",
    "            x = Dense(x.shape[-1]*2, activation=LeakyReLU())(x)\n",
    "\n",
    "        x = concatenate([x, self.label_inp])\n",
    "        x = Dense(np.prod(self.HIDDEN_IMG_SHAPE), activation=LeakyReLU())(x)\n",
    "        x = Reshape(self.HIDDEN_IMG_SHAPE)(x)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        for _ in range(6):\n",
    "            x = Conv2DTranspose(self.FILTERS_GEN, (3, 3), activation=LeakyReLU())(x)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "        generated_img = Conv2D(3, (3, 3), activation=\"tanh\")(x)\n",
    "\n",
    "        self.generator = Model([self.latent_space_inp, self.label_inp], generated_img, name=\"generator\")\n",
    "\n",
    "    def batch_gen(self, batch_size, dataset):\n",
    "        \"\"\"Чтобы использовать \"big_flowers_dataset\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "        train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            image_size=self.IMG_SHAPE[:-1],\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            # Добавляем лейблы (т.к. у нас CCGAN) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "            # (т.к. с sigmoid градиент затухает)\n",
    "            x, y = next(iter(train_data))\n",
    "            x = x / 127.5 -1\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.LATENT_DIM))\n",
    "\n",
    "            yield x, y, noise\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        row, column = 2, self.NUM_CLASSES\n",
    "        noise = np.random.normal(0, 1, (row * column, self.LATENT_DIM))\n",
    "        label = np.array([\n",
    "            np.arange(0, self.NUM_CLASSES) for _ in range(row)\n",
    "        ]).reshape((-1, 1))\n",
    "        sampled_labels = keras.utils.to_categorical(label, self.NUM_CLASSES)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels], verbose=False)\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        gen_imgs -= np.min(gen_imgs)\n",
    "        gen_imgs /= np.max(gen_imgs)\n",
    "\n",
    "        # Делаем картинку\n",
    "        fig, axs = plt.subplots(row, column, figsize=(12, 6))\n",
    "        count = 0\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                axs[i, j].imshow(gen_imgs[count, :, :, :])\n",
    "                axs[i, j].set_title(label[count][0])\n",
    "                axs[i, j].axis(\"off\")\n",
    "                count += 1\n",
    "        fig.savefig(\"generated_flowers/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def train(self, batch_size=32, dataset=\"flowers_dataset\"):\n",
    "        # # Просто единицы и нули для Дискриминатора\n",
    "        # valid = np.ones((batch_size, 1))\n",
    "        # fake = np.zeros((batch_size, 1))\n",
    "        #\n",
    "        # get_batch = self.batch_gen(batch_size=batch_size, dataset=dataset)\n",
    "        #\n",
    "        # epoch_count = 1\n",
    "        # all_l_dis = [0]\n",
    "        # all_l_gen = [0]\n",
    "        #\n",
    "        # for learn_iter in range(int(10**10)):\n",
    "        #     # Обучение дискриминатора\n",
    "        #     for _ in range(1 + (self.HANDICAP if np.mean(all_l_dis)-0.15 > np.mean(all_l_gen) else 0)):\n",
    "        #         images, labels, noise = next(get_batch)\n",
    "        #         with tf.GradientTape() as dis_tape:\n",
    "        #             dis_real_output = self.discriminator([images, labels], training=True)\n",
    "        #             generated_images = self.generator([noise, labels], training=False)\n",
    "        #             dis_fake_output = self.discriminator([generated_images, labels], training=True)\n",
    "        #\n",
    "        #             # Чем настоящие картинки нереальнее или сгенерированные реальные, тем ошибка больше\n",
    "        #             l_dis = 0.5 * (tf.reduce_mean(-tf.math.log(dis_real_output + 1e-9)) +\n",
    "        #                            tf.reduce_mean(-tf.math.log(1. - dis_fake_output + 1e-9)))\n",
    "        #\n",
    "        #         all_l_dis.append(l_dis)\n",
    "        #\n",
    "        #         # Получаем градиенты для дискриминатора\n",
    "        #         grads_dis = dis_tape.gradient(l_dis, self.discriminator.trainable_variables)\n",
    "        #         self.optimizer_dis.apply_gradients(zip(grads_dis, self.discriminator.trainable_variables))\n",
    "        #\n",
    "        #     # Обучение генератора\n",
    "        #     for _ in range(1 + (self.HANDICAP if np.mean(all_l_gen)-0.15 > np.mean(all_l_dis) else 0)):\n",
    "        #         images, labels, noise = next(get_batch)\n",
    "        #         with tf.GradientTape() as gen_tape:\n",
    "        #             generated_images = self.generator([noise, labels], training=True)\n",
    "        #             dis_output = self.discriminator([generated_images, labels], training=False)\n",
    "        #\n",
    "        #             # Чем более реалистичная картина (для дискриминатора), тем меньше ошибка\n",
    "        #             l_gen = -tf.reduce_mean(tf.math.log(dis_output + 1e-9))\n",
    "        #\n",
    "        #         all_l_gen.append(l_gen)\n",
    "        #\n",
    "        #         # Получаем градиенты для генератора\n",
    "        #         grads_gen = gen_tape.gradient(l_gen, self.generator.trainable_variables)\n",
    "        #         self.optimizer_gen.apply_gradients(zip(grads_gen, self.generator.trainable_variables))\n",
    "        #\n",
    "        #     # Сохраняем генерируемые образцы каждую эпоху\n",
    "        #     if learn_iter % (2800 // batch_size) == 0:\n",
    "        #         self.sample_images(epoch_count)\n",
    "        #\n",
    "        #         # Вывод прогресса и средних ошибок\n",
    "        #         print(f\"{epoch_count:02} \\t\"\n",
    "        #               f\"[Dis loss: {np.mean(all_l_dis):.3f}] \\t\"\n",
    "        #               f\"[Gen loss: {np.mean(all_l_gen):.3f}]\")\n",
    "        #\n",
    "        #         epoch_count += 1\n",
    "        #         all_l_dis = [0]\n",
    "        #         all_l_gen = [0]\n",
    "\n",
    "        train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            image_size=self.IMG_SHAPE[:-1],\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "        valid = np.ones(shape=(2799, 1))\n",
    "        fake = np.zeros(shape=(2799, 1))\n",
    "\n",
    "        for i in range(1, 10**10):\n",
    "            images = np.array([x[0]/255.*2 - 1 for x, y in train_data])\n",
    "            labels = np.array([y[0] for x, y in train_data])\n",
    "            noise = np.random.randint(0, 1, size=(2799, self.LATENT_DIM))\n",
    "\n",
    "            generated_images = self.generator.predict([noise, labels])\n",
    "            self.discriminator.fit([generated_images, labels], fake)\n",
    "            self.discriminator.fit([images, labels], valid)\n",
    "            self.ccgan.fit([noise, labels], valid)\n",
    "\n",
    "            self.sample_images(i)\n",
    "\n",
    "\n",
    "ccgan = CCGAN()\n",
    "print(\"Generator:    \", f\"{ccgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{ccgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{ccgan.generator.count_params() + ccgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T10:53:44.961126900Z",
     "start_time": "2024-06-06T10:53:44.413127900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 files belonging to 5 classes.\n",
      " 1/88 [..............................] - ETA: 3:17"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mccgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mflowers_dataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 236\u001B[0m, in \u001B[0;36mCCGAN.train\u001B[1;34m(self, batch_size, dataset)\u001B[0m\n\u001B[0;32m    233\u001B[0m labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([y[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m train_data])\n\u001B[0;32m    234\u001B[0m noise \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2799\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLATENT_DIM))\n\u001B[1;32m--> 236\u001B[0m generated_images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mfit([generated_images, labels], fake)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mfit([images, labels], valid)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\keras\\engine\\training.py:2253\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2251\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   2252\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m-> 2253\u001B[0m     tmp_batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2254\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   2255\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    955\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    956\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    957\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ccgan.train(batch_size=32, dataset=\"flowers_dataset\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T10:53:57.451067800Z",
     "start_time": "2024-06-06T10:53:48.836061500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
