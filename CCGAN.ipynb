{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T07:44:28.408398400Z",
     "start_time": "2024-05-28T07:44:26.834216800Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 192, 192, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_78 (MaxPooling2D  (None, 96, 96, 3)   0           ['image[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 96, 96, 3)    0           ['max_pooling2d_78[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 94, 94, 64)   1792        ['dropout_85[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 92, 92, 64)   36928       ['conv2d_262[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_79 (MaxPooling2D  (None, 46, 46, 64)  0           ['conv2d_263[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 46, 46, 64)   0           ['max_pooling2d_79[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 44, 44, 64)   36928       ['dropout_86[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_264[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_80 (MaxPooling2D  (None, 21, 21, 64)  0           ['conv2d_265[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 21, 21, 64)   0           ['max_pooling2d_80[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 19, 19, 64)   36928       ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 17, 17, 64)   36928       ['conv2d_266[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_81 (MaxPooling2D  (None, 8, 8, 64)    0           ['conv2d_267[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 8, 8, 64)     0           ['max_pooling2d_81[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 6, 6, 64)     36928       ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 4, 4, 64)     36928       ['conv2d_268[0][0]']             \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 1024)         0           ['conv2d_269[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 1029)         0           ['label[0][0]',                  \n",
      "                                                                  'flatten_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            1030        ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 261,318\n",
      "Trainable params: 261,318\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " latent_space (InputLayer)      [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 21)           0           ['label[0][0]',                  \n",
      "                                                                  'latent_space[0][0]']           \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 9025)         198550      ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_15 (Reshape)           (None, 95, 95, 1)    0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 190, 190, 1)  0          ['reshape_15[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 190, 190, 1)  0           ['up_sampling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 192, 192, 64  640        ['dropout_89[0][0]']             \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 194, 194, 64  36928      ['conv2d_transpose_2[0][0]']     \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 192, 192, 3)  1731        ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 237,849\n",
      "Trainable params: 237,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Generator:     237,849\n",
      "Discriminator: 261,318\n",
      "Sum:           499,167\n"
     ]
    }
   ],
   "source": [
    "# Удаляем все прошлые изображения\n",
    "for i in os.listdir(\"./generated_flowers\"):\n",
    "    os.remove(f\"./generated_flowers/{i}\")\n",
    "\n",
    "class CCGAN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.NUM_CLASSES = 5  # Не менять!\n",
    "\n",
    "        # Входные форматы\n",
    "        self.IMG_SHAPE = (192, 192, 3)\n",
    "        self.LATENT_DIM = 16\n",
    "\n",
    "        # Константы\n",
    "        self.FILTERS = 64\n",
    "        self.DROPOUT = 0.05\n",
    "        self.HIDDEN_IMG_SHAPE = (95, 95, 1)\n",
    "        self.HANDICAP = 5  # Фора в опережении одной из нейронок перед другой\n",
    "\n",
    "        # Чем меньше тем лучше:\n",
    "        self.AMOUNT_DISCRIMINATOR_LAYERS = 4\n",
    "        self.AMOUNT_GENERATOR_LAYERS = None\n",
    "\n",
    "        \"\"\"\n",
    "        Генератор и Дискриминатор\n",
    "        \"\"\"\n",
    "        # Мучаемся со входами\n",
    "        self.image_inp = Input(shape=self.IMG_SHAPE, name=\"image\")\n",
    "        self.label_inp = Input(shape=(self.NUM_CLASSES,), name=\"label\")\n",
    "        self.latent_space_inp = Input(shape=(self.LATENT_DIM,), name=\"latent_space\")\n",
    "\n",
    "        # Создаём дискриминатор\n",
    "        self.build_discriminator()\n",
    "        self.discriminator.summary()\n",
    "        # Создаём генератор\n",
    "        self.build_generator()\n",
    "        self.generator.summary()\n",
    "\n",
    "        \"\"\"\n",
    "        Модели\n",
    "        \"\"\"\n",
    "        # z == latten_space\n",
    "        self.generated_z = self.generator([self.latent_space_inp, self.label_inp])\n",
    "        self.dis_gen_z = self.discriminator([self.generated_z, self.label_inp])\n",
    "\n",
    "        ccgan_model = Model([self.latent_space_inp, self.label_inp], self.dis_gen_z, name=\"CCGAN\")\n",
    "        self.ccgan = ccgan_model([self.latent_space_inp, self.label_inp])\n",
    "\n",
    "        self.optimizer_gen = Adam(1e-4)\n",
    "        self.optimizer_dis = Adam(1e-4)\n",
    "\n",
    "    def build_discriminator(self) -> Model:\n",
    "        x = self.image_inp\n",
    "\n",
    "        for i in range(self.AMOUNT_DISCRIMINATOR_LAYERS)[::-1]:\n",
    "            x = MaxPool2D()(x)\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            x = Conv2D(self.FILTERS, (3, 3), activation=LeakyReLU())(x)\n",
    "            x = Conv2D(self.FILTERS, (3, 3), activation=LeakyReLU())(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        # # Постепенно сжимаем\n",
    "        # dense_units = x.shape[-1] // 2\n",
    "        # while dense_units > 1:\n",
    "        #     x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "        #     x = Dense(dense_units, activation=LeakyReLU())(x)\n",
    "        #     dense_units //= 2\n",
    "\n",
    "        x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.discriminator = Model([self.image_inp, self.label_inp], x, name=\"discriminator\")\n",
    "\n",
    "    def build_generator(self) -> Model:\n",
    "        x = self.latent_space_inp\n",
    "\n",
    "        # # Постепенно разжимаем от размера скрытого вектора до hidden_img_shape\n",
    "        # dense_units = self.LATENT_DIM * 2\n",
    "        # while dense_units * 2 <= np.prod(self.HIDDEN_IMG_SHAPE):\n",
    "        #     x = Dropout(self.DROPOUT)(x)\n",
    "        #     x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "        #     x = Dense(dense_units, activation=LeakyReLU())(x)\n",
    "        #     dense_units *= 2\n",
    "\n",
    "        # Разжимаем вектор признаков в маленькую картинку\n",
    "        x = concatenate([self.label_inp, x])\n",
    "        x = Dense(np.prod(self.HIDDEN_IMG_SHAPE), activation=LeakyReLU())(x)\n",
    "        x = Reshape(self.HIDDEN_IMG_SHAPE)(x)\n",
    "        x = UpSampling2D()(x)\n",
    "\n",
    "        x = Dropout(self.DROPOUT)(x)\n",
    "        x = Conv2DTranspose(self.FILTERS, (3, 3), activation=\"tanh\")(x)\n",
    "        x = Conv2DTranspose(self.FILTERS, (3, 3), activation=\"tanh\")(x)\n",
    "\n",
    "        generated_img = Conv2D(3, (3, 3), activation=\"tanh\")(x)\n",
    "        self.generator = Model([self.latent_space_inp, self.label_inp], generated_img, name=\"generator\")\n",
    "\n",
    "    def batch_gen(self, batch_size, dataset):\n",
    "        \"\"\"Чтобы использовать \"big_flowers_dataset\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "        train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            image_size=self.IMG_SHAPE[:-1],\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            # Добавляем лейблы (т.к. у нас CCGAN) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "            # (т.к. с sigmoid градиент затухает)\n",
    "            x, y = next(iter(train_data))\n",
    "            x = x / 127.5 -1\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.LATENT_DIM))\n",
    "\n",
    "            yield x, y, noise\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        row, column = 2, self.NUM_CLASSES\n",
    "        noise = np.random.normal(0, 1, (row * column, self.LATENT_DIM))\n",
    "        label = np.array([\n",
    "            np.arange(0, self.NUM_CLASSES) for _ in range(row)\n",
    "        ]).reshape((-1, 1))\n",
    "        sampled_labels = keras.utils.to_categorical(label, self.NUM_CLASSES)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels], verbose=False)\n",
    "        gen_imgs = (gen_imgs + 1) / 2\n",
    "\n",
    "        # Делаем картинку\n",
    "        fig, axs = plt.subplots(row, column, figsize=(12, 6))\n",
    "        count = 0\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                axs[i, j].imshow(gen_imgs[count, :, :, :])\n",
    "                axs[i, j].set_title(label[count][0])\n",
    "                axs[i, j].axis(\"off\")\n",
    "                count += 1\n",
    "        fig.savefig(\"generated_flowers/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def train(self, batch_size=32, dataset=\"flowers_dataset\"):\n",
    "        # Просто единицы и нули для Дискриминатора\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        get_batch = self.batch_gen(batch_size=batch_size, dataset=dataset)\n",
    "\n",
    "        epoch_count = 0\n",
    "        all_l_dis = [0]\n",
    "        all_l_gen = [0]\n",
    "\n",
    "        for learn_iter in range(int(10**10)):\n",
    "            # Если Генератор обыгрывает Дискриминатор, то обучаем Дискриминатор\n",
    "            iters = self.HANDICAP if np.mean(all_l_dis) > np.mean(all_l_gen) else 1\n",
    "            for _ in range(iters):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as dis_tape:\n",
    "                    dis_real_output = self.discriminator([images, labels], training=True)\n",
    "                    generated_images = self.generator([noise, labels], training=False)\n",
    "                    dis_fake_output = self.discriminator([generated_images, labels], training=True)\n",
    "\n",
    "                    # Чем настоящие картинки нереальнее или сгенерированные реальные, тем ошибка больше\n",
    "                    l_dis = 0.5 * (tf.reduce_mean(-tf.math.log(dis_real_output + 1e-9)) +\n",
    "                                   tf.reduce_mean(-tf.math.log(1. - dis_fake_output + 1e-9)))\n",
    "\n",
    "                all_l_dis.append(l_dis)\n",
    "\n",
    "                # Получаем градиенты для дискриминатора\n",
    "                grads_dis = dis_tape.gradient(l_dis, self.discriminator.trainable_variables)\n",
    "                self.optimizer_dis.apply_gradients(zip(grads_dis, self.discriminator.trainable_variables))\n",
    "\n",
    "\n",
    "            # Если Дискриминатор обыгрывает Генератор, то больше обучаем Генератор\n",
    "            iters = self.HANDICAP if np.mean(all_l_gen) > np.mean(all_l_dis) else 1\n",
    "            for _ in range(iters):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as gen_tape:\n",
    "                    generated_images = self.generator([noise, labels], training=True)\n",
    "                    dis_output = self.discriminator([generated_images, labels], training=False)\n",
    "\n",
    "                    # Чем более реалистичная картина (для дискриминатора), тем меньше ошибка\n",
    "                    l_gen = -tf.reduce_mean(tf.math.log(dis_output + 1e-9))\n",
    "\n",
    "                all_l_gen.append(l_gen)\n",
    "\n",
    "                # Получаем градиенты для генератора\n",
    "                grads_gen = gen_tape.gradient(l_gen, self.generator.trainable_variables)\n",
    "                self.optimizer_gen.apply_gradients(zip(grads_gen, self.generator.trainable_variables))\n",
    "\n",
    "            # ______________________________\n",
    "            # Сохраняем генерируемые образцы каждую эпоху\n",
    "            if learn_iter % (2800 // batch_size) == 0:\n",
    "                self.sample_images(epoch_count)\n",
    "\n",
    "                # Вывод прогресса и средних ошибок\n",
    "                print(f\"{epoch_count:02} \\t\"\n",
    "                      f\"[Dis loss: {np.mean(all_l_dis):.3f}] \\t\"\n",
    "                      f\"[Gen loss: {np.mean(all_l_gen):.3f}]\")\n",
    "\n",
    "                epoch_count += 1\n",
    "                all_l_dis = [0]\n",
    "                all_l_gen = [0]\n",
    "\n",
    "ccgan = CCGAN()\n",
    "print(\"Generator:    \", f\"{ccgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{ccgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{ccgan.generator.count_params() + ccgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T09:56:20.614765600Z",
     "start_time": "2024-05-28T09:56:20.438480300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T10:45:35.443505400Z",
     "start_time": "2024-05-28T09:56:21.766261200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 files belonging to 5 classes.\n",
      "00 \t[Dis loss: 0.345] \t[Gen loss: 0.347]\n",
      "01 \t[Dis loss: 0.587] \t[Gen loss: 0.665]\n",
      "02 \t[Dis loss: 0.661] \t[Gen loss: 0.684]\n",
      "03 \t[Dis loss: 0.698] \t[Gen loss: 0.717]\n",
      "04 \t[Dis loss: 0.636] \t[Gen loss: 0.722]\n",
      "05 \t[Dis loss: 0.691] \t[Gen loss: 1.026]\n",
      "06 \t[Dis loss: 0.672] \t[Gen loss: 0.873]\n",
      "07 \t[Dis loss: 0.654] \t[Gen loss: 0.764]\n",
      "08 \t[Dis loss: 0.659] \t[Gen loss: 0.798]\n",
      "09 \t[Dis loss: 0.686] \t[Gen loss: 0.762]\n",
      "10 \t[Dis loss: 0.645] \t[Gen loss: 0.670]\n",
      "11 \t[Dis loss: 0.698] \t[Gen loss: 1.027]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Temp\\ipykernel_12980\\564143224.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mccgan\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"flowers_dataset\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Temp\\ipykernel_12980\\1151636567.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, batch_size, dataset)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    173\u001B[0m             \u001B[1;31m# Если Дискриминатор обыгрывает Генератор, то больше обучаем Генератор\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m             \u001B[0miters\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mHANDICAP\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_l_gen\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_l_dis\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 176\u001B[1;33m                 \u001B[0mimages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    177\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mGradientTape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mgen_tape\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    178\u001B[0m                     \u001B[0mgenerated_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnoise\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m                     \u001B[0mdis_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiscriminator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mgenerated_images\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Temp\\ipykernel_12980\\1151636567.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, batch_size, dataset)\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m             \u001B[1;31m# Добавляем лейблы (т.к. у нас CCGAN) и нормализуем в [-1; 1], т.к. юзаем tanh\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m             \u001B[1;31m# (т.к. с sigmoid градиент затухает)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m             \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m127.5\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m             \u001B[0mnoise\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLATENT_DIM\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m   1421\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1422\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1423\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1424\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1425\u001B[1;33m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 155\u001B[1;33m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1180\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1181\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mOpDispatcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNOT_SUPPORTED\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1183\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1184\u001B[1;33m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   1586\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1587\u001B[0m   \u001B[0mRaises\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1588\u001B[0m     \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mx\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0my\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mhave\u001B[0m \u001B[0mdifferent\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1589\u001B[0m   \"\"\"\n\u001B[1;32m-> 1590\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0m_truediv_python3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   1524\u001B[0m           f\"of {{{', '.join([repr(x) for x in _TRUEDIV_TABLE.keys()])}}}.\")\n\u001B[0;32m   1525\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1526\u001B[0m       \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1527\u001B[0m       \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1528\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreal_div\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   7872\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7873\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7874\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7875\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 7876\u001B[1;33m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   7877\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7878\u001B[0m       _result = _dispatcher_for_real_div(\n\u001B[0;32m   7879\u001B[0m           (x, y, name,), None)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ccgan.train(batch_size=32, dataset=\"flowers_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Выводим Архитектуру\"\"\"\n",
    "encoder_img = tf.keras.utils.plot_model(encoder, to_file=\"encoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)\n",
    "\n",
    "decoder_img = tf.keras.utils.plot_model(decoder, to_file=\"decoder.png\", show_shapes=False, show_layer_names=False,\n",
    "                                        dpi=128, show_layer_activations=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccgan.save_weights(\"ccgan\")\n",
    "# ccgan.load_weights(\"ccgan\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
