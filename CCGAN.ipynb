{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:26:04.413781800Z",
     "start_time": "2024-06-02T15:26:02.955836700Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "from math import log2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 88, 88, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 23232)        0           ['image[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         47581184    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         2098176     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          524800      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          131328      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          32896       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           2080        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 16)           528         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 8)            136         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 8)            0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4)            36          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 4)            0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 2)            10          ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 2)            0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            3           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6)            0           ['label[0][0]',                  \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1)            7           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,379,440\n",
      "Trainable params: 50,379,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " latent_space (InputLayer)      [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 2)            0           ['latent_space[0][0]']           \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 4)            12          ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 4)            0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            40          ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 8)            0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 16)           144         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 16)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 32)           544         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32)           0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 64)           2112        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 64)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          8320        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 256)          33024       ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 256)          0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 512)          131584      ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 512)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1024)         525312      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 1024)         0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 2048)         2099200     ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 23232)        47602368    ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 88, 88, 3)    0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,402,660\n",
      "Trainable params: 50,402,660\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Generator:     50,402,660\n",
      "Discriminator: 50,379,440\n",
      "Sum:           100,782,100\n"
     ]
    }
   ],
   "source": [
    "# Удаляем все прошлые изображения\n",
    "for i in os.listdir(\"./generated_flowers\"):\n",
    "    os.remove(f\"./generated_flowers/{i}\")\n",
    "\n",
    "class CCGAN(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.NUM_CLASSES = 5  # Не менять!\n",
    "\n",
    "        # Входные форматы\n",
    "        self.IMG_SHAPE = (88, 88, 3)\n",
    "        self.LATENT_DIM = 2\n",
    "        self.HANDICAP = 0  # Фора чтобы одна иишка не отставала от другой\n",
    "\n",
    "        # Константы\n",
    "        self.FILTERS_DIS = 2048   # Нижняя граница\n",
    "        self.FILTERS_GEN = 2048\n",
    "        self.DROPOUT = 0.0\n",
    "        self.HIDDEN_IMG_SHAPE = (80, 80, 1)\n",
    "\n",
    "        # Чем меньше тем лучше:\n",
    "        self.AMOUNT_DISCRIMINATOR_LAYERS = 3\n",
    "        self.AMOUNT_GENERATOR_LAYERS = 3\n",
    "\n",
    "        \"\"\"\n",
    "        Генератор и Дискриминатор\n",
    "        \"\"\"\n",
    "        # Мучаемся со входами\n",
    "        self.image_inp = Input(shape=self.IMG_SHAPE, name=\"image\")\n",
    "        self.label_inp = Input(shape=(self.NUM_CLASSES,), name=\"label\")\n",
    "        self.latent_space_inp = Input(shape=(self.LATENT_DIM,), name=\"latent_space\")\n",
    "\n",
    "        # Создаем дискриминатор\n",
    "        self.build_discriminator()\n",
    "        self.discriminator.summary()\n",
    "        # Создаем генератор\n",
    "        self.build_generator()\n",
    "        self.generator.summary()\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.decode_loss_tracker = keras.metrics.Mean(name=\"decode_loss\")\n",
    "        self.bias_loss_tracker = keras.metrics.Mean(name=\"bias_loss\")\n",
    "\n",
    "        \"\"\"\n",
    "        Модели\n",
    "        \"\"\"\n",
    "        # z == latten_space\n",
    "        self.generated_z = self.generator([self.latent_space_inp, self.label_inp])\n",
    "        self.dis_gen_z = self.discriminator([self.generated_z, self.label_inp])\n",
    "\n",
    "        ccgan_model = Model([self.latent_space_inp, self.label_inp], self.dis_gen_z, name=\"CCGAN\")\n",
    "        self.ccgan = ccgan_model([self.latent_space_inp, self.label_inp])\n",
    "\n",
    "        self.optimizer_gen = Adam(1e-2)\n",
    "        self.optimizer_dis = Adam(1e-2)\n",
    "\n",
    "    def build_discriminator(self) -> Model:\n",
    "        # # Объединяем картинку с лейблами\n",
    "        # x = Embedding(self.NUM_CLASSES, self.IMG_SHAPE[0]**2)(self.label_inp)\n",
    "        # x = Reshape([*self.IMG_SHAPE[:2], self.NUM_CLASSES])(x)\n",
    "        # x = concatenate([self.image_inp, x])\n",
    "        #\n",
    "        # for i in range(1, self.AMOUNT_DISCRIMINATOR_LAYERS +1):\n",
    "        #     x = AveragePooling2D()(x)\n",
    "        #     x = Dropout(self.DROPOUT)(x)\n",
    "        #     x = Conv2D(self.FILTERS_DIS * 2**i, (11, 11), activation=\"tanh\")(x)\n",
    "        #     x = BatchNormalization()(x)\n",
    "        #\n",
    "        # while x.shape[1] >= 3:\n",
    "        #     x = Dropout(self.DROPOUT)(x)\n",
    "        #     x = Conv2D(x.shape[-1], (3, 3), activation=\"tanh\")(x)\n",
    "        #\n",
    "        # x = Flatten()(x)\n",
    "        #\n",
    "        # # Постепенно сжимаем\n",
    "        # dense_units = x.shape[-1] // 2\n",
    "        # while dense_units >= 4:\n",
    "        #     x = Dropout(self.DROPOUT)(x)\n",
    "        #     x = concatenate([self.label_inp, x])  # Добавляем метки класса\n",
    "        #     x = Dense(dense_units, activation=\"tanh\")(x)\n",
    "        #     dense_units //= 2\n",
    "\n",
    "        x = Flatten()(self.image_inp)\n",
    "        x = Dense(self.FILTERS_DIS, activation=\"tanh\")(x)\n",
    "\n",
    "        while x.shape[-1] >= 2:\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            x = Dense(x.shape[-1] // 2, activation=\"tanh\")(x)\n",
    "\n",
    "        # Добавляем метки класса\n",
    "        x = concatenate([self.label_inp, x])\n",
    "        x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        self.discriminator = Model([self.image_inp, self.label_inp], x, name=\"discriminator\")\n",
    "\n",
    "    def build_generator(self) -> Model:\n",
    "        # # Разжимаем вектор шума в маленькую картинку\n",
    "        # x = self.latent_space_inp\n",
    "        #\n",
    "        # for _ in range(self.AMOUNT_GENERATOR_LAYERS):\n",
    "        #     x = Dropout(self.DROPOUT)(x)\n",
    "        #     x = concatenate([x, self.label_inp])\n",
    "        #     x = Dense(x.shape[-1]*2, activation=\"tanh\")(x)\n",
    "        #\n",
    "        # x = concatenate([x, self.label_inp])\n",
    "        # x = Dense(np.prod(self.HIDDEN_IMG_SHAPE), activation=\"tanh\")(x)\n",
    "        # x = Reshape(self.HIDDEN_IMG_SHAPE)(x)\n",
    "        #\n",
    "        # x = UpSampling2D()(x)\n",
    "        # x = Conv2DTranspose(self.FILTERS_GEN, (11, 11), activation=\"tanh\")(x)\n",
    "        # x = BatchNormalization()(x)\n",
    "        #\n",
    "        # generated_img = Conv2D(3, (1, 1), activation=\"tanh\")(x)\n",
    "\n",
    "        x = self.latent_space_inp\n",
    "        while x.shape[-1] < self.FILTERS_GEN:\n",
    "            x = Dropout(self.DROPOUT)(x)\n",
    "            x = Dense(x.shape[-1] * 2, activation=\"tanh\")(x)\n",
    "\n",
    "        x = Dense(np.prod(self.IMG_SHAPE), activation=\"tanh\")(x)\n",
    "        generated_img = Reshape(self.IMG_SHAPE)(x)\n",
    "\n",
    "        self.generator = Model([self.latent_space_inp, self.label_inp], generated_img, name=\"generator\")\n",
    "\n",
    "    def batch_gen(self, batch_size, dataset):\n",
    "        \"\"\"Чтобы использовать \"big_flowers_dataset\" (расширенный датасет) надо запустить increasing_data.py\"\"\"\n",
    "        train_data = keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset,\n",
    "            image_size=self.IMG_SHAPE[:-1],\n",
    "            label_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            # Добавляем лейблы (т.к. у нас CCGAN) и нормализуем в [-1; 1], т.к. юзаем tanh\n",
    "            # (т.к. с sigmoid градиент затухает)\n",
    "            x, y = next(iter(train_data))\n",
    "            x = x / 127.5 -1\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.LATENT_DIM))\n",
    "\n",
    "            yield x, y, noise\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        row, column = 2, self.NUM_CLASSES\n",
    "        noise = np.random.normal(0, 1, (row * column, self.LATENT_DIM))\n",
    "        label = np.array([\n",
    "            np.arange(0, self.NUM_CLASSES) for _ in range(row)\n",
    "        ]).reshape((-1, 1))\n",
    "        sampled_labels = keras.utils.to_categorical(label, self.NUM_CLASSES)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels], verbose=False)\n",
    "        gen_imgs = np.array(gen_imgs)\n",
    "        gen_imgs -= np.min(gen_imgs)\n",
    "        gen_imgs /= np.max(gen_imgs)\n",
    "\n",
    "        # Делаем картинку\n",
    "        fig, axs = plt.subplots(row, column, figsize=(12, 6))\n",
    "        count = 0\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                axs[i, j].imshow(gen_imgs[count, :, :, :])\n",
    "                axs[i, j].set_title(label[count][0])\n",
    "                axs[i, j].axis(\"off\")\n",
    "                count += 1\n",
    "        fig.savefig(\"generated_flowers/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def train(self, batch_size=32, dataset=\"flowers_dataset\"):\n",
    "        # Просто единицы и нули для Дискриминатора\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        get_batch = self.batch_gen(batch_size=batch_size, dataset=dataset)\n",
    "\n",
    "        epoch_count = 1\n",
    "        all_l_dis = [0]\n",
    "        all_l_gen = [0]\n",
    "\n",
    "        for learn_iter in range(int(10**10)):\n",
    "            # Обучение дискриминатора\n",
    "            for _ in range(1 + (self.HANDICAP if np.mean(all_l_dis)-0.15 > np.mean(all_l_gen) else 0)):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as dis_tape:\n",
    "                    dis_real_output = self.discriminator([images, labels], training=True)\n",
    "                    generated_images = self.generator([noise, labels], training=False)\n",
    "                    dis_fake_output = self.discriminator([generated_images, labels], training=True)\n",
    "\n",
    "                    # Чем настоящие картинки нереальнее или сгенерированные реальные, тем ошибка больше\n",
    "                    l_dis = 0.5 * (tf.reduce_mean(-tf.math.log(dis_real_output + 1e-9)) +\n",
    "                                   tf.reduce_mean(-tf.math.log(1. - dis_fake_output + 1e-9)))\n",
    "\n",
    "                all_l_dis.append(l_dis)\n",
    "\n",
    "                # Получаем градиенты для дискриминатора\n",
    "                grads_dis = dis_tape.gradient(l_dis, self.discriminator.trainable_variables)\n",
    "                self.optimizer_dis.apply_gradients(zip(grads_dis, self.discriminator.trainable_variables))\n",
    "\n",
    "            # Обучение генератора\n",
    "            for _ in range(1 + (self.HANDICAP if np.mean(all_l_gen)-0.15 > np.mean(all_l_dis) else 0)):\n",
    "                images, labels, noise = next(get_batch)\n",
    "                with tf.GradientTape() as gen_tape:\n",
    "                    generated_images = self.generator([noise, labels], training=True)\n",
    "                    dis_output = self.discriminator([generated_images, labels], training=False)\n",
    "\n",
    "                    # Чем более реалистичная картина (для дискриминатора), тем меньше ошибка\n",
    "                    l_gen = -tf.reduce_mean(tf.math.log(dis_output + 1e-9))\n",
    "\n",
    "                all_l_gen.append(l_gen)\n",
    "\n",
    "                # Получаем градиенты для генератора\n",
    "                grads_gen = gen_tape.gradient(l_gen, self.generator.trainable_variables)\n",
    "                self.optimizer_gen.apply_gradients(zip(grads_gen, self.generator.trainable_variables))\n",
    "\n",
    "            # Сохраняем генерируемые образцы каждую эпоху\n",
    "            if learn_iter % (2800 // batch_size) == 0:\n",
    "                self.sample_images(epoch_count)\n",
    "\n",
    "                # Вывод прогресса и средних ошибок\n",
    "                print(f\"{epoch_count:02} \\t\"\n",
    "                      f\"[Dis loss: {np.mean(all_l_dis):.3f}] \\t\"\n",
    "                      f\"[Gen loss: {np.mean(all_l_gen):.3f}]\")\n",
    "\n",
    "                epoch_count += 1\n",
    "                all_l_dis = [0]\n",
    "                all_l_gen = [0]\n",
    "\n",
    "\n",
    "ccgan = CCGAN()\n",
    "print(\"Generator:    \", f\"{ccgan.generator.count_params():,}\")\n",
    "print(\"Discriminator:\", f\"{ccgan.discriminator.count_params():,}\")\n",
    "print(\"Sum:          \", f\"{ccgan.generator.count_params() + ccgan.discriminator.count_params():,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:26:05.337880900Z",
     "start_time": "2024-06-02T15:26:04.505229700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 files belonging to 5 classes.\n",
      "01 \t[Dis loss: 0.368] \t[Gen loss: 0.287]\n",
      "02 \t[Dis loss: 0.626] \t[Gen loss: 0.542]\n",
      "03 \t[Dis loss: 0.588] \t[Gen loss: 0.660]\n",
      "04 \t[Dis loss: 0.543] \t[Gen loss: 0.777]\n",
      "05 \t[Dis loss: 0.536] \t[Gen loss: 0.825]\n",
      "06 \t[Dis loss: 0.589] \t[Gen loss: 0.720]\n",
      "07 \t[Dis loss: 0.629] \t[Gen loss: 0.656]\n",
      "08 \t[Dis loss: 0.625] \t[Gen loss: 0.759]\n",
      "09 \t[Dis loss: 0.621] \t[Gen loss: 0.766]\n",
      "10 \t[Dis loss: 0.624] \t[Gen loss: 0.744]\n",
      "11 \t[Dis loss: 0.619] \t[Gen loss: 0.716]\n",
      "12 \t[Dis loss: 0.616] \t[Gen loss: 0.703]\n",
      "13 \t[Dis loss: 0.612] \t[Gen loss: 0.694]\n",
      "14 \t[Dis loss: 0.621] \t[Gen loss: 0.693]\n",
      "15 \t[Dis loss: 0.618] \t[Gen loss: 0.691]\n",
      "16 \t[Dis loss: 0.615] \t[Gen loss: 0.693]\n",
      "17 \t[Dis loss: 0.618] \t[Gen loss: 0.687]\n",
      "18 \t[Dis loss: 0.615] \t[Gen loss: 0.681]\n",
      "19 \t[Dis loss: 0.617] \t[Gen loss: 0.695]\n",
      "20 \t[Dis loss: 0.611] \t[Gen loss: 0.691]\n",
      "21 \t[Dis loss: 0.617] \t[Gen loss: 0.688]\n",
      "22 \t[Dis loss: 0.610] \t[Gen loss: 0.696]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1061\u001B[0m, in \u001B[0;36m_EagerTensorBase.__float__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1059\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m long(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numpy())\n\u001B[1;32m-> 1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__float__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1062\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numpy())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mccgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mflowers_dataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 200\u001B[0m, in \u001B[0;36mCCGAN.train\u001B[1;34m(self, batch_size, dataset)\u001B[0m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_dis\u001B[38;5;241m.\u001B[39mapply_gradients(\u001B[38;5;28mzip\u001B[39m(grads_dis, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiscriminator\u001B[38;5;241m.\u001B[39mtrainable_variables))\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# Обучение генератора\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mHANDICAP \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(all_l_gen)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.15\u001B[39m \u001B[38;5;241m>\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_l_dis\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)):\n\u001B[0;32m    201\u001B[0m     images, labels, noise \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(get_batch)\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m gen_tape:\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _methods\u001B[38;5;241m.\u001B[39m_mean(a, axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   3505\u001B[0m                       out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\miniconda3\\envs\\main\\lib\\site-packages\\numpy\\core\\_methods.py:102\u001B[0m, in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 102\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    104\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    106\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "ccgan.train(batch_size=256, dataset=\"flowers_dataset\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T15:29:20.784500600Z",
     "start_time": "2024-06-02T15:26:05.338881200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Выводим Архитектуру\"\"\"\n",
    "generator_img = tf.keras.utils.plot_model(ccgan.generator, to_file=\"images/generator.png\", show_shapes=False,\n",
    "                                          show_layer_names=False, dpi=128, show_layer_activations=False)\n",
    "\n",
    "discriminator_img = tf.keras.utils.plot_model(ccgan.discriminator, to_file=\"images/discriminator.png\", show_shapes=False,\n",
    "                                              show_layer_names=False, dpi=128, show_layer_activations=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
